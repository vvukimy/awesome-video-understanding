# awesome-video-understanding
A curated list of resources (paper, code, data) on video understanding research.

---
**Table of Contents**
- [Models](#models)
  - [Video LLMs](#video-llms)
  - [Agents](#agents)
- [Benchmarks](#benchmarks)
  - [QA](#qa)
  - [Caption](#caption)
  - [Temporal-Grounding](#temporal-grounding)
  - [Hallucination](#hallucination)
- [Datasets](#datasets)
  - [Pre-Training](#pre-training)
  - [Instruction-Tuning](#instruction-tuning)
  - [RLHF](#rlhf)
- [Research Topics](#research-topics)
---

## Models
### Video LLMs
| Name | Paper | Task | Note |
|:---|:---|:---|:---|
| **LLaVA-Video**<br>@ByteDance | [Video Instruction Tuning with Synthetic Data](https://arxiv.org/abs/2410.02713)<br>24.10.03 / ArXiv / [Code](https://llava-vl.github.io/blog/2024-09-30-llava-video/) | Video-QA<br>Video-Caption | / |
### Agents
| Name | Paper | Task | Note |
|:---|:---|:---|:---|
|  |  |  |  |

## Benchmarks
### QA
| Name | Paper | Metadata | Note |
|:---|:---|:---|:---|
|  |  |  |  |
### Caption
| Name | Paper | Metadata | Note |
|:---|:---|:---|:---|
|  |  |  |  |
### Temporal-Grounding
| Name | Paper | Metadata | Note |
|:---|:---|:---|:---|
|  |  |  |  |
### Hallucination
| Name | Paper | Metadata | Note |
|:---|:---|:---|:---|
|  |  |  |  |

## Datasets
### Pre-Training
| Name | Paper | Data | Metadata |
|:---|:---|:---|:---|
|  |  |  |  |
### Instruction-Tuning
| Name | Paper | Data | Metadata |
|:---|:---|:---|:---|
| **LLaVA-Video-178k**<br>@ByteDance |  [Video Instruction Tuning with Synthetic Data](https://arxiv.org/abs/2410.02713)<br>24.10.03 / ArXiv / [Project](https://llava-vl.github.io/blog/2024-09-30-llava-video/)| [Dataset](https://huggingface.co/datasets/lmms-lab/LLaVA-Video-178K) | Duration: 0~3min <br> Caption: 178K <br> QA: 1.1M |
### RLHF
| Name | Paper | Data | Metadata |
|:---|:---|:---|:---|
|  |  |  |  |

## Research Topics
